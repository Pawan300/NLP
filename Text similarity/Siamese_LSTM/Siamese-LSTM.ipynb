{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "file1_similarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wLnu_eYZwXh",
        "outputId": "96cc2e79-9147-4fcf-e045-e6930339887b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/My\\ Drive/Colab\\ Notebooks/NLP/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/NLP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLd--k44Z-uv",
        "outputId": "6189788e-0aeb-4988-ab33-42fadc1f798b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file1_similarity.ipynb  model_dir.zip            Untitled0.ipynb\n",
            "file2_similarity.ipynb  \u001b[0m\u001b[01;34mmultihead-siamese-nets\u001b[0m/\n",
            "file3_similarity.ipynb  \u001b[01;34mSiamese-LSTM\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCiewG_halZO"
      },
      "source": [
        "# !git clone https://github.com/likejazz/Siamese-LSTM.git"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M73r87uias83",
        "outputId": "2d47def0-29c5-47eb-f92d-12442058d1da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd Siamese-LSTM/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/NLP/Siamese-LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq78AUSjayc2",
        "outputId": "7a2ac27c-ec90-4c60-9726-14a664e09e34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  predict.py  \u001b[01;34m__pycache__\u001b[0m/  README.md  train.py  util.py  word2vec.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WXNkzS0CoUX",
        "outputId": "18290420-13fd-40c2-fadd-50f149a4cb88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd, gensim\n",
        "from gensim.models import KeyedVectors\n",
        "from tensorflow import keras\n",
        "from util import ManDist, make_w2v_embeddings, split_and_zero_padding\n",
        "\n",
        "from time import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.keras.models import Model, Sequential\n",
        "from tensorflow.python.keras.layers import Input, Embedding, LSTM, GRU, Conv1D, Conv2D, GlobalMaxPool1D, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from util import make_w2v_embeddings\n",
        "from util import split_and_zero_padding\n",
        "from util import ManDist"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhSmB2CP_KuQ",
        "outputId": "a6fc8da3-3ff1-427c-c2ca-413966674b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "word2vec = KeyedVectors.load_word2vec_format(\"./data/GoogleNews-vectors-negative300.bin.gz\", binary=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9sDns40Rw74",
        "outputId": "bc2b54a6-1e0d-4e0a-8d4e-30549dce1ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# File paths\n",
        "TRAIN_CSV = './data/questions.csv'\n",
        "\n",
        "# Load training set\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "for q in ['question1', 'question2']:\n",
        "    train_df[q + '_n'] = train_df[q]\n",
        "\n",
        "# Make word2vec embeddings\n",
        "embedding_dim = 300\n",
        "max_seq_length = 20\n",
        "use_w2v = True\n",
        "\n",
        "train_df, embeddings = make_w2v_embeddings(train_df, word2vec, \n",
        "                                           vector=True, embedding_dim=embedding_dim, \n",
        "                                           empty_w2v=not use_w2v)\n",
        "\n",
        "validation_size = int(len(train_df) * 0.1)\n",
        "training_size = len(train_df) - validation_size\n",
        "\n",
        "X = train_df[['question1_n', 'question2_n']]\n",
        "Y = train_df['is_duplicate']\n",
        "\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, \n",
        "                                                                Y, test_size=validation_size)\n",
        "\n",
        "X_train = split_and_zero_padding(X_train, max_seq_length)\n",
        "X_validation = split_and_zero_padding(X_validation, max_seq_length)\n",
        "\n",
        "# Convert labels to their numpy representations\n",
        "Y_train = Y_train.values\n",
        "Y_validation = Y_validation.values\n",
        "\n",
        "# Make sure everything is ok\n",
        "assert X_train['left'].shape == X_train['right'].shape\n",
        "assert len(X_train['left']) == len(Y_train)\n",
        "\n",
        "# Model variables\n",
        "batch_size = 64\n",
        "n_epoch = 40\n",
        "n_hidden = 50\n",
        "\n",
        "# Define the shared model\n",
        "x = Sequential()\n",
        "x.add(Embedding(len(embeddings), embedding_dim,\n",
        "                weights=[embeddings], input_shape=(max_seq_length,), trainable=False))\n",
        "x.add(tf.keras.layers.Bidirectional(\n",
        "        tf.keras.layers.LSTM(64, dropout=0.2, return_sequences=True)\n",
        "    ))\n",
        "shared_model = x\n",
        "\n",
        "# The visible layer\n",
        "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "\n",
        "# Pack it all up into a Manhattan Distance model\n",
        "malstm_distance = ManDist()([shared_model(left_input), shared_model(right_input)])\n",
        "model = Model(inputs=[left_input, right_input], outputs=[malstm_distance])\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "model.summary()\n",
        "shared_model.summary()\n",
        "\n",
        "early = EarlyStopping(monitor='val_loss',mode='auto', baseline=None, restore_best_weights=False)\n",
        "# Start trainings\n",
        "training_start_time = time()\n",
        "malstm_trained = model.fit([X_train['left'], X_train['right']], Y_train,\n",
        "                           batch_size=batch_size, epochs=n_epoch,\n",
        "                           validation_data=([X_validation['left'], X_validation['right']], Y_validation),\n",
        "                            callbacks=[early])\n",
        "training_end_time = time()\n",
        "print(\"Training time finished.\\n%d epochs in %12.2f\" % (n_epoch,\n",
        "                                                        training_end_time - training_start_time))\n",
        "\n",
        "model.save('./data/SiameseLSTM.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'gensim.models.keyedvectors.Word2VecKeyedVectors'>\n",
            "Loading word2vec model(it may takes 2-3 mins) ...\n",
            "10,000 sentences embedded.\n",
            "20,000 sentences embedded.\n",
            "30,000 sentences embedded.\n",
            "40,000 sentences embedded.\n",
            "50,000 sentences embedded.\n",
            "60,000 sentences embedded.\n",
            "70,000 sentences embedded.\n",
            "80,000 sentences embedded.\n",
            "90,000 sentences embedded.\n",
            "100,000 sentences embedded.\n",
            "110,000 sentences embedded.\n",
            "120,000 sentences embedded.\n",
            "130,000 sentences embedded.\n",
            "140,000 sentences embedded.\n",
            "150,000 sentences embedded.\n",
            "160,000 sentences embedded.\n",
            "170,000 sentences embedded.\n",
            "180,000 sentences embedded.\n",
            "190,000 sentences embedded.\n",
            "200,000 sentences embedded.\n",
            "210,000 sentences embedded.\n",
            "220,000 sentences embedded.\n",
            "230,000 sentences embedded.\n",
            "240,000 sentences embedded.\n",
            "250,000 sentences embedded.\n",
            "260,000 sentences embedded.\n",
            "270,000 sentences embedded.\n",
            "280,000 sentences embedded.\n",
            "290,000 sentences embedded.\n",
            "300,000 sentences embedded.\n",
            "310,000 sentences embedded.\n",
            "320,000 sentences embedded.\n",
            "330,000 sentences embedded.\n",
            "340,000 sentences embedded.\n",
            "350,000 sentences embedded.\n",
            "360,000 sentences embedded.\n",
            "370,000 sentences embedded.\n",
            "380,000 sentences embedded.\n",
            "390,000 sentences embedded.\n",
            "400,000 sentences embedded.\n",
            "Index(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate',\n",
            "       'question1_n', 'question2_n'],\n",
            "      dtype='object')\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 20, 128)      25949380    input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "man_dist_1 (ManDist)            (None, 1, 128)       0           sequential_1[1][0]               \n",
            "                                                                 sequential_1[2][0]               \n",
            "==================================================================================================\n",
            "Total params: 25,949,380\n",
            "Trainable params: 186,880\n",
            "Non-trainable params: 25,762,500\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 20, 300)           25762500  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 20, 128)           186880    \n",
            "=================================================================\n",
            "Total params: 25,949,380\n",
            "Trainable params: 186,880\n",
            "Non-trainable params: 25,762,500\n",
            "_________________________________________________________________\n",
            "Train on 363916 samples, validate on 40435 samples\n",
            "Epoch 1/40\n",
            "363916/363916 [==============================] - 927s 3ms/sample - loss: 0.2570 - acc: 0.0116 - val_loss: 0.2829 - val_acc: 0.0547\n",
            "Epoch 2/40\n",
            "363916/363916 [==============================] - 972s 3ms/sample - loss: 0.2488 - acc: 0.0104 - val_loss: 0.2756 - val_acc: 0.0549\n",
            "Epoch 3/40\n",
            "363916/363916 [==============================] - 973s 3ms/sample - loss: 0.2472 - acc: 0.0103 - val_loss: 0.2769 - val_acc: 0.0554\n",
            "Training time finished.\n",
            "40 epochs in      2875.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df7KHmpx01_a"
      },
      "source": [
        "model = keras.models.load_model(\"./data/SiameseLSTM.h5\", custom_objects={'ManDist':ManDist})"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNUvhfk61UgP",
        "outputId": "44642d13-4380-4513-de2a-904413dac75b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sentence1 = \"Reports that the NSA eavesdropped on world leaders have \\\"severely shaken\\\" relations between Europe and the U.S., German Chancellor Angela Merkel said.\"\n",
        "sentence2 = \"Germany and France are to seek talks with the US to settle a row over spying, as espionage claims continue to overshadow an EU summit in Brussels.\"\n",
        "\n",
        "test_df = pd.DataFrame(data = {'question1': sentence1, 'question2': sentence2, \n",
        "                               'question1_n': sentence1, 'question2_n': sentence2}, index =[1])\n",
        "\n",
        "embedding_dim = 300\n",
        "max_seq_length = 20\n",
        "test_df, embeddings = make_w2v_embeddings(test_df, word2vec, vector=True, embedding_dim=embedding_dim, empty_w2v=False)\n",
        "\n",
        "# Split to dicts and append zero padding.\n",
        "X_test = split_and_zero_padding(test_df, max_seq_length)\n",
        "\n",
        "# Make sure everything is ok\n",
        "assert X_test['left'].shape == X_test['right'].shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'gensim.models.keyedvectors.Word2VecKeyedVectors'>\n",
            "Loading word2vec model(it may takes 2-3 mins) ...\n",
            "Index(['question1', 'question2', 'question1_n', 'question2_n'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJILYFMZ1zC0",
        "outputId": "83b531ae-289f-4864-b30e-8cf2c0f30367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "pred = model.predict([X_test['left'], X_test['right']])\n",
        "print(\"Sentence 1: {}\\n Sentence 2: {}\\n Similarity Score: {} \".\n",
        "      format(sentence1, sentence2, np.average(pred, axis=2)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence 1: Reports that the NSA eavesdropped on world leaders have \"severely shaken\" relations between Europe and the U.S., German Chancellor Angela Merkel said.\n",
            " Sentence 2: Germany and France are to seek talks with the US to settle a row over spying, as espionage claims continue to overshadow an EU summit in Brussels.\n",
            " Similarity Score: [[0.48394203]] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPQh4oSVY7ip"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}