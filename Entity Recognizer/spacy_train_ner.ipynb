{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spacy_train_ner.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j5b5aoptrgn"
      },
      "source": [
        "fact= {\n",
        "'O' : \"Outside\", \n",
        "'B-geo' : \"Geographical Entity\",\n",
        "'B-gpe' : \"Geopolitical Entity\", \n",
        "'B-per' : \"PERSON\",\n",
        "'I-geo' : \"Geographical Entity\",                  # B- Begining \n",
        "'B-org' : \"ORGANIZATION\",                         # I - Inside\n",
        "'I-org' : \"ORGANIZATION\", \n",
        "'B-tim' : \"TIME\",\n",
        "'B-art' : \"Artifact\", \n",
        "'I-art' : \"Artifact\", \n",
        "'I-per' : \"PERSON\", \n",
        "'I-gpe' : \"Geopolitical Entity\", \n",
        "'I-tim' : \"TIME\", \n",
        "'B-nat' : \"Natural Phenomenon\", \n",
        "'B-eve' : \"Event\",\n",
        "'I-eve' : \"Event\",\n",
        "'I-nat' : \"Natural Phenomenon\"\n",
        " }"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSJM6leKM7As",
        "outputId": "4ca19b31-8922-4db0-80ad-1cf02825f14b"
      },
      "source": [
        "import nltk\n",
        "import random\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzSdDPC6sQ3B"
      },
      "source": [
        "# SPACY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhob1StXsOAy"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/NLP/data_ner.csv\")\n",
        "data = data.iloc[:-1]\n",
        "data = data.fillna(method=\"ffill\", axis=0)"
      ],
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdE6MpgL-s6H"
      },
      "source": [
        "LABEL = list(data[\"Tag\"].unique())"
      ],
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LITYLyKWsdDu",
        "outputId": "2c6e12a0-448c-485c-cd80-794d35c717bd"
      },
      "source": [
        "data = data.groupby([\"Sentence #\"], as_index=False\n",
        "             )[\"Word\", \"POS\", \"Tag\"].agg(lambda x: list(x))"
      ],
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAcCG4FWuxt3"
      },
      "source": [
        "def create_data(index):\n",
        "  \n",
        "  position = 0\n",
        "  a = data[\"Tag\"].iloc[index]\n",
        "  temp = []\n",
        "\n",
        "  for j in range(len(a)):\n",
        "    \n",
        "    if a[j]!=\"O\":\n",
        "\n",
        "      temp.append((position, position + len(data[\"Word\"].iloc[j]) , a[j]))\n",
        "    position += len(data[\"Word\"].iloc[j])\n",
        "  return temp\n",
        "\n",
        "# creating datatset according to the spacy requirements\n",
        "\n",
        "dataset = []\n",
        "for i in range(data.shape[0]):\n",
        "\n",
        "  content = \" \".join(data.iloc[i][\"Word\"])\n",
        "  entities = create_data(i)\n",
        "\n",
        "  dataset.append(\n",
        "            (\n",
        "                content, {\n",
        "                    \"entities\" : entities\n",
        "                }\n",
        "            )\n",
        "  )"
      ],
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QvdldPX53UI",
        "outputId": "43427959-6c3a-4e57-ba6e-9186b9169cb3"
      },
      "source": [
        "# Setting up the pipeline and entity recognizer.\n",
        "model = None\n",
        "if model is not None:\n",
        "    nlp = spacy.load(model)  # load existing spacy model\n",
        "    print(\"Loaded model '%s'\" % model)\n",
        "else:\n",
        "    nlp = spacy.blank('en')  # create blank Language class\n",
        "    print(\"Created blank 'en' model\")\n",
        "if 'ner' not in nlp.pipe_names:\n",
        "    ner = nlp.create_pipe('ner')\n",
        "    nlp.add_pipe(ner)\n",
        "else:\n",
        "    ner = nlp.get_pipe('ner')"
      ],
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created blank 'en' model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEG4I6AU53t3"
      },
      "source": [
        "for i in LABEL:\n",
        "    ner.add_label(i)\n",
        "# Inititalizing optimizer\n",
        "if model is None:\n",
        "    optimizer = nlp.begin_training()\n",
        "else:\n",
        "    optimizer = nlp.entity.create_optimizer()"
      ],
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLLZpQzE_wop"
      },
      "source": [
        "from spacy.util import minibatch, compounding"
      ],
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQRItEjg-ovm"
      },
      "source": [
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "\n",
        "TRAIN_DATA = dataset\n",
        "n_iter = 10\n",
        "\n",
        "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "    for itn in range(n_iter):\n",
        "        print(\"Iteration \",itn,\" #\"*100)\n",
        "        random.shuffle(TRAIN_DATA)\n",
        "        losses = {}\n",
        "        batches = minibatch(TRAIN_DATA, \n",
        "                            size=compounding(4., 32., 1.001))\n",
        "        for batch in batches:\n",
        "            texts, annotations = zip(*batch) \n",
        "            # Updating the weights\n",
        "            nlp.update(texts, annotations, sgd=optimizer, \n",
        "                       drop=0.35, losses=losses)\n",
        "            print('Losses', losses)\n",
        "            nlp.update(texts, annotations, sgd=optimizer, \n",
        "                       drop=0.35, losses=losses)\n",
        "            print('Losses', losses)"
      ],
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb3IaTHuCjIQ",
        "outputId": "6a349de5-3f7d-463b-951f-0b66acc738c3"
      },
      "source": [
        "output_dir = \"/content/drive/MyDrive/Colab Notebooks/NLP\"\n",
        "if output_dir is not None:\n",
        "    output_dir = Path(output_dir)\n",
        "    if not output_dir.exists():\n",
        "        output_dir.mkdir()\n",
        "    nlp.meta['name'] = \"spacy_101_ner\"  # rename model\n",
        "    nlp.to_disk(output_dir)\n",
        "    print(\"Saved model to\", output_dir)"
      ],
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to /content/drive/MyDrive/Colab Notebooks/NLP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "z87yFXruBa7g",
        "outputId": "f4289c86-c3d1-40db-82e7-f4f8b736bd0c"
      },
      "source": [
        "print(\"Loading from\", output_dir)\n",
        "nlp2 = spacy.load(output_dir)\n",
        "doc2 = nlp2(\"\"\"Prime Minister Jacinda Ardern has claimed that New Zealand had won a big \n",
        "battle over the spread of coronavirus. Her words came as the country begins to exit from its lockdown.\"\"\")\n",
        "displacy.render(doc2, style = 'ent', jupyter=True)"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading from /content/drive/MyDrive/Colab Notebooks/NLP\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Prime Minister \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jacinda Ardern\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has claimed that \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    New Zealand\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " had won a big \n",
              "battle over the spread of coronavirus. Her words came as the country begins to exit from its lockdown.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mplx85BNOjpY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}